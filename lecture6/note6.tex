%!TEX root = main6.tex

\newcommand{\PRF}{\ensuremath{{\sf PRF}}}
\newcommand{\FHE}{\ensuremath{{\sf FHE}}}
\newcommand{\Gen}{\ensuremath{{\sf Gen}}}
\newcommand{\Eval}{\ensuremath{{\sf Eval}}}
\newcommand{\DpfGen}{\ensuremath{{\sf DPF.Gen}}}
\newcommand{\DpfEval}{\ensuremath{{\sf DPF.Eval}}}
\newcommand{\Enc}{\ensuremath{{\sf Enc}}}
\newcommand{\Dec}{\ensuremath{{\sf Dec}}}
\newcommand{\Dpf}{\ensuremath{{\sf DPF}}}
\newcommand{\DPF}{\ensuremath{{\sf DPF}}}
\newcommand{\Prg}{\ensuremath{{\sf PRG}}}
\newcommand{\Pbc}{\ensuremath{{\sf PBC}}}
\newcommand{\Seed}{\ensuremath{{\sf Seed}}}
\newcommand{\DB}{\ensuremath{{\sf DB}}}
\newcommand{\Comm}{\ensuremath{{\sf Comm}}}
\newcommand{\GenSched}{\ensuremath{{\sf GenSchedule}}}
\newcommand{\ServerPre}{\ensuremath{{\sf ServerPreprocess}}}
\newcommand{\ClientQ}{\ensuremath{{\sf ClientQuery}}}
\newcommand{\ServerA}{\ensuremath{{\sf ServerAnswer}}}
\newcommand{\ClientD}{\ensuremath{{\sf ClientDecode}}}
\newtheorem{notation}{Notation}
\newcommand{\xor}{\ensuremath{\oplus}}
\newcommand{\Sim}{\ensuremath{{\sf Sim}}}
\newcommand{\negl}{\ensuremath{{\sf negl}}}
\newcommand{\get}{\ensuremath{\leftarrow}}
\newcommand{\Client}{\textsf{Client}~}
\newcommand{\Server}{\textsf{Server}~}
\newcommand{\CV}{\ensuremath{{\sf CV}}}
\newcommand{\key}{\ensuremath{{\sf key}}}
\newcommand{\getr}{\ensuremath{~{\overset{\$}{\leftarrow}}}~}
\newcommand{\ignore}[1]{}
\renewcommand{\root}{\ensuremath{{\sf root}}}

\newcommand{\elaine}[1]{{\color{red} [elaine: #1]}}
\newcommand{\mingxun}[1]{{\color{red} [mz: #1]}}

\section{Distributed Point Function and 2-server PIR with Logarithmic Communication} %~\cite{boyle2016function}}

In earlier lectures, we learned an information-theoretic 2-server PIR
scheme 
by Dvir and Gopi~\cite{dvir20162}, which
achieves $n^{O(\sqrt{\log \log n / \log n})}$ communication per query. 
%We saw that in the IT-setting, the best known upper bound on the communication of 2-server PIR scheme is by Dvir and Gopi~\cite{dvir20162}.
%The scheme achieves $n^{O(\sqrt{\log \log n / \log n})}$ communication.
In this lecture, 
we will show how to get a 2-server PIR with logarithmic communication
%from only one-way functions (OWF).
relying only on a pseudorandom 
generator (PRG). This scheme is also interesting from a practical perspective
since in practice, we can use AES to realize
the PRG, and modern CPUs have hardware acceleration
for evaluating AES. 

Recall that 
from our undergraduate cryptography course, 
we know that the existence of a PRG
is equivalent to the existence of a one-way function (OWF)~\cite{haastad1999pseudorandom}.
Also, from an earlier lecture, we learned that any 1-server
classical PIR scheme 
with non-trivial bandwidth implies
Oblivious Transfer which cannot be constructed
in a blackbox manner from OWF~\cite{IR89}. 
Therefore, the scheme we will talk about today is in the 2-server setting.

%that if we are willing to assume that one-way functions (OWF) exist, we can construct a 2-server PIR scheme with $O(\log n)$ communication.
%\mingxun{I am not sure what other sschemes you want to compare to. The IT one seems to be the most appropriate one}

\subsection{Preliminary: Pseudorandom Generator}
%This scheme use pseudorandom generators (PRG). In particular, PRG implies the existence of OWF and OWF implies the existence of PRG~\cite{haastad1999pseudorandom}. 
We will rely on a pseudorandom generator (PRG),
which takes in a short random seed and expands
the seed to a longer pseudorandom string.

\begin{definition}[PRG]
    Let $\ell(\cdot)$ be a polynomial and let 
$G:  \{0,1\}^n \rightarrow \{0,1\}^{\ell(n)}$ be a deterministic
    polynomial-time algorithm. $G$ is a \Prg \ if it has the following properties:
    \hfill
    \begin{itemize}
        \item \textbf{Expansion:} $\forall n, \ell(n) > n$.
        \item \textbf{Pseudorandomness:} for any probabilistic polynomial-time distinguisher
$D$, there exists a negligible function ${\sf negl}(\cdot)$, 
such that 
        $$\left|\Pr_{r \getr \{0, 1\}^{\ell(n)}}\left[D(r) = 1\right] - 
\Pr_{s \getr \{0, 1\}^{n}}\left[D(G(s)) = 1\right]\right| \leq {\sf negl}(n)$$ 
        %Where $r \overset{{\scriptscriptstyle\$}}{\leftarrow} \{0,1\}^{l(n)}$ and
        %$s \overset{{\scriptscriptstyle\$}}{\leftarrow} \{0,1\}^{n}$.
    \end{itemize}
\end{definition}

\subsection{Distributed Point Function}

\begin{definition}[Point function]
A point function parametrized by some point $x \in \{0, 1\}^\ell$ 
is a function that evaluates to $1$ at $x$, and evaluates to $0$ 
everywhere else.
We will henceforth use the notation $P_x \{0,1\}^{\ell} \rightarrow \{0,1\}$
to denote a point function. 
By definition, $P_x(x) = 1$ and $P_x(x') = 0$ for $x' \neq x$.
%    For $x \in\{0,1\}^*$, the point function $P_{x}:\{0,1\}^{|{x}|} \rightarrow \{0,1\}$
%    is defined by $P_{x^*}(x^*) = 1 \ and \ P_{x^*}(x) = 0$ for all $x \neq x^*$.
\end{definition}

Boyle, Gilboa and Ishai~\cite{boyle2016function} introduced the concept of distributed point function. 
We are going to focus on the case of a 2-share binary distributed point function. 
Essentially, given the full description of the point function $P_{x^*}$, one can ``secretly share'' the function to two keys $k_0,k_1$. Then, if party $t\in\{0,1\}$ receives $k_t$, it can evaluate the function on all possible location $x$ and get an evaluation of $\Eval(k_t, x)$. 
It is guaranteed that in every location $x'$, $\Eval(k_0, x)\xor\Eval(k_1, x)=P_{x^*}(x)$.
Also, each party $t$ has no information about the ``special location'' (i.e., $x^*$) given the key $k_t$.


\begin{definition}[2-share binary \Dpf]
    A DPF is a pair of PPT algorithms (\Gen,\Eval) with the following syntax:
    \hfill
    \begin{itemize}
        \item $\Gen(1^\lambda,x^*)$: Outputs a pair of keys $k_0,k_1$.
        \item $\Eval(1^\lambda, k,x)$: Outputs $y \in \{0,1\}$
    \end{itemize}
    \paragraph{Correctness.} $\Pr[k_0,k_1 \leftarrow \Gen(1^\lambda, x^*):\Eval(k_0,x) \oplus \Eval(k_1,x) = P_{x^*}(x)] = 1$.
    \paragraph{Security.} Given $t\in\{0,1\}$ and any $x^*\in \{0,1\}^{\ell(\lambda)}$, there exists a PPT simulator $\Sim$, such that the following experiments are computationally indistinguishable:
    \begin{itemize}
        \item $\mathsf{Real}(1^\lambda, x^*)$: $k_0,k_1\get  \Gen(1^\lambda, x^*)$ and output $k_t$;
        \item $\mathsf{Ideal}(1^\lambda)$: Output $\Sim(1^\lambda, \ell)$.
    \end{itemize}
\end{definition}


\subsection{2-server PIR scheme based on DPF}

Let $\DB \in \{0,1\}^{n}, i \in [n]$ and $\lambda$ be the security parameter.
Suppose we have an efficient 2-share binary DPF scheme $\DpfGen$ and $\DpfEval$, such that the key length is $O_\lambda(\log n)$ (where $n$ is the size of the input domain), and the evaluation algorithm is efficient. 
Then, we can have the following 2-server PIR scheme. %n the following, when the context is clear, we will omit $1^\lambda$ in the description.

\begin{enumerate}
    \item Given the query $i$, \Client computes $(k_0,k_1) \leftarrow \DPF.\Gen(1^\lambda, i)$
    \item \Client sends $(k_0,k_1)$ to \Server 0 and \Server 1 respectively.
    \item For $t\in\{0,1\}$, \Server $t$ responds with $y_i \leftarrow \bigoplus_{j\in [n]} \DPF.\Eval(k_t,j)\cdot \DB[j]$;
    \item \Client computes the answer as $y_0 \oplus y_1$.
\end{enumerate}

\paragraph{Correctness} 
\begin{align*} 
    y_0 \oplus y_1 & = \left(\bigoplus_{j}\DB[j]\cdot \DpfEval(k_0,j) \right) \oplus \left(\bigoplus_{j}\mathsf{DB}[j]\cdot \DPF.\Eval(k_1,j) \right) \\
    & = \left(\bigoplus_{j}\DB[j]\cdot (\DpfEval(k_0,j)\xor \DPF.\Eval(k_1,j)) \right) \\
    & = \left(\bigoplus_{j}\DB[j]\cdot P_{i}(j)\right) \\
    & = \DB[i].
\end{align*}
\paragraph{Security}
Security follows from the security of the DPF.



\subsubsection{DPF construction using PRG}



\begin{figure}
    
    \begin{minipage}{\textwidth}
        \begin{mdframed}
            \begin{center}
                \textbf{(New Version) Generation Algorithm:} $\Gen(1^\lambda, x^*)$
            \end{center}
            
            \paragraph{Initialization:} 
            %Repeat the following process $m$ times (indexed by $j$):
            \begin{itemize}
                \item Sample $s_0$, $s_1$ as two $\lambda$-bit random strings. 
                \item Sample a random bit $b_0$. Let $b_1=b_0\xor 1$. 
                \item Let $\{x^*[1],\dots,x^*[\log n]\}$ be $x^*$'s binary representation.
                \item Store the roots: let $(\root.s_0,\root.b_0)=(s_0,b_0)$ and $(\root.s_1,\root.b_1)=(s_1,b_1)$.
            \end{itemize}
            
            
            \paragraph{Constructing correction vectors:} 
            For $i\in \{1,\dots, \log n\}$: 
                \begin{itemize}
                    \item If $x^*[i]=0$, set ${\sf Keep}=L$. Otherwise, set ${\sf Keep}=R$.
                    \item Sample a random string $r\getr \{0,1\}^{\lambda}$.
                    \item Set $\CV_i\in\{0,1\}^{2\lambda+2}$ as an unknown variable and build the equation as follows.
                    \begin{itemize}
                        \item Let $s^0_L || b^0_L || s^0_R || b^0_R\get G(s_0) \xor (b_0 \cdot \CV_i)$; \hfill \textit{Expanding the first key}
                        \item Let $s^1_L || b^1_L || s^1_R || b^1_R\get G(s_1) \xor (b_1 \cdot \CV_i)$; \hfill \textit{Expanding the second key}
                        \item If ${\sf Keep}=L$: set the invariant as 
                        \begin{align*}
                            (s^0_L || b^0_L || s^0_R || b^0_R) \xor (s^1_L || b^1_L || s^1_R || b^1_R) = (r || 1 || 0^{\lambda} || 0).
                        \end{align*}
                       
                        \item If ${\sf Keep}=R$: set the invariant as 
                        \begin{align*}
                            (s^0_L || b^0_L || s^0_R || b^0_R) \xor (s^1_L || b^1_L || s^1_R || b^1_R) = (0^{\lambda} || 0 || r || 1).
                        \end{align*}
                        \hfill \textit{(Force the ${\sf Keep}$ direction to be different and the other direction to be identical.)}
                    \end{itemize}
                    \item Solve the equation based on the invariant to get $\CV_i$. The equation is always solvable.
                    \item Update $(s_0, b_0) \get (s^0_{\sf Keep}, b^0_{\sf Keep})$;
                    \item Update $(s_1, b_1) \get (s^1_{\sf Keep}, b^1_{\sf Keep})$;
                \end{itemize}  
            \paragraph{Output:} Output $k_0, k_1$:
            \begin{align*}
                k_0=(\root.s_0, \root.b_0, \CV_1,\dots,\CV_{\log n}) \\
                k_1=(\root.s_1, \root.b_1, \CV_1,\dots,\CV_{\log n})
            \end{align*}
            
        \end{mdframed}
    \end{minipage}
    \caption{The 2-share binary DPF generation algorithm.\label{fig:DPF}}
    %\caption{Detailed description of \name.\label{fig:single-server}}
\end{figure}

\begin{figure}
    
    \begin{minipage}{\textwidth}
        \begin{mdframed}
            \begin{center}
                \textbf{Generation Algorithm:} $\Gen(1^\lambda, x^*)$
            \end{center}
            
            \paragraph{Initialization:} 
            %Repeat the following process $m$ times (indexed by $j$):
            \begin{itemize}
                \item Sample $s_0$, $s_1$ as two $\lambda$-bit random strings. 
                \item Sample a random bit $b_0$. Let $b_1=b_0\xor 1$.
                \item Let $k_0 = (s_0, b_0)$ and $k_1=(s_1,b_1)$;
                \item Let $\{x^*[1],\dots,x^*[\log n]\}$ be $x^*$'s binary representation. 
            \end{itemize}
            
            
            \paragraph{Constructing correction vectors:} 
            
            
            For $i\in \{1,\dots, \log n\}$: 
            \begin{itemize}
                \item Let $s^0_L || b^0_L || s^0_R || b^0_R\get G(s_0)$;
                \item Let $s^1_L || b^1_L || s^1_R || b^1_R\get G(s_1)$;
                \item Let $s_L || b_L || s_R || b_R=(s^0_L || b^0_L || s^0_R || b^0_R) \xor (s^1_L || b^1_L || s^1_R || b^1_R)$;
                \item Sample $r$ as a random $\lambda$-bit random string;
                \item If $x^*[i]=0$: 
                \begin{itemize}
                    \item Let $\CV_i =~ r ~|| (b_L \xor 1) || s_R || b_R$; \hfill 
                    \item Update $(s_0 || b_0) \get (s^0_L || b^0_L) \xor (b_0 \cdot (r ~|| (b_L \xor 1)))$;
                    \item Update $(s_1 || b_1) \get (s^1_L || b^1_L) \xor (b_1 \cdot (r ~|| (b_L \xor 1)))$;
                    %\item $(s_1 || b_1) \get (s^1_L || b^1_L) \xor (b_1 \cdot (r ~|| (b^*_L \xor 1)))$;
                \end{itemize}
                \item If $x^*[i]=1$: 
                \begin{itemize}
                    \item Let $\CV_i = s_L || b_L || ~r ~|| (b_R \xor 1)$;\hfill %\textit{If the path goes right}; 
                    \item Update $(s_0 || b_0) \get (s^0_R || b^0_L) \xor (b_0 \cdot (r ~|| (b_R \xor 1)))$;
                    \item Update $(s_1 || b_1) \get (s^1_R || b^1_R) \xor (b_1 \cdot (r ~|| (b_R \xor 1)))$;
                \end{itemize}
                %\item Expand $(s_0, b_0), (s_1, b_1)$ to their children as the same as the expansion algorithm, using $\CV_i$. Update $(s_0, b_0), (s_1, b_1)$ by replacing them with their children's pairs (only the pairs on the special path).  
            \end{itemize}
            
            \paragraph{Output:}
            \begin{itemize}
                \item Attach $\CV_1,\dots,\CV_{\log n}$ to $k_0$ and $k_1$.
                \item Output $k_0,k_1$.
            \end{itemize}
            
        \end{mdframed}
    \end{minipage}
    \caption{The 2-share binary DPF generation algorithm.\label{fig:DPF}}
    %\caption{Detailed description of \name.\label{fig:single-server}}
\end{figure}

\begin{figure*}
    \centering
    \includegraphics[scale=0.4]{scribimg_dpftree.png}
    \caption{An example of the DPF construction.\label{fig:example-DPF}}
\end{figure*}



Now we see how to construct this efficient 2-share binary DPF, based on a \Prg~$G$:
 $$G: \{0,1\}^{\lambda} \rightarrow  \{0,1\}^{2\lambda + 2}. $$
The algorithm is based on a binary tree expansion idea.
%Where the series of evaluation results can be visualized as a binary tree.
 
\paragraph{The key structure.} The $\Gen$ algorithm outputs two keys, $k_0, k_1$. For each key $k_t$ where $t\in\{0,1\}$, it contains the ``root'' information as a $\lambda$-bit random string $s$ and a bit $b\in\{0,1\}$. It also contains $\log n$ ``correction vectors'' $\CV_1, \dots, \CV_{\log n}$, each of size $2\lambda+2$ bit. $k_0, k_1$ will share the same sets of correction vectors. 
We will see how they are constructed later. 


\paragraph{Evaluation algorithm.} 
Given a key containing $s,b$ and $\CV_1,\dots,\CV_{\log n}$, the evaluation algorithm is as follows.
We consider a binary tree with $\log n + 1$ levels and $n$ leaves (assume $n$ is a power of 2). 
The root is on the $0$-th level and the leaves are on the $\log n$-th level.
Each node contains a $\lambda$-bit (pseudo)random string $ s \in \{0,1\}^{\lambda}$ and a bit $b \in \{0,1\}$. 
The root's string and bit are included in the description of the key.
For all other nodes, their strings and bits will be decided by their parents.
Given a node on level $(i-1)$, suppose now we want to decide the bits and the strings of its children (on level $i$). 
We only need the following one-line algorithm:
 $$ s_{L} || b_{L} || s_{R} || b_{R} \leftarrow G(s) \oplus
 \begin{cases} 
    0 & b = 0; \\
    \CV_i & b = 1. \\
 \end{cases}$$
That is, $s_{L}, b_{L}$ are the string and bit on its left child, and $s_{R}, b_{R}$ are the string and bit on its right child.
Finally, the bit on the $i$-th leaf will be $\Eval(k, i)$.

Notice that if we only want to learn $\Eval(k, i)$ for a particular $i$, the computation cost will be $O(\log n)$ calls to the PRG, because we can focus on the path from the root to the $i$-th leaf and ignore other nodes.
%And on the path we only do $\log n$ expansions.
However, if we want to evaluate $\Eval(k, i)$ for all $i\in[n]$, the computation cost will be $O(n)$ because we can simply do the expansion on the whole tree. 


\paragraph{Generation Algorithm.} The generation algorithm needs to generate two correlated keys, such that when we look at the bit at the $x$-th leaves (say $b^0_{x}$ and $b^1_{x}$) on the trees expnaded by $k_0$ and $k_1$, it must that $b^0_{x}\xor b^1_{x}=P_{x^*}(x)$. In fact, we want to ensure the following stronger properties.
Say on a particular node, we denote the information expanded by $k_0$ and $k_1$ as $(s_0,b_0)$ and $(s_1,b_1)$, respectively.
\begin{enumerate}
    \item If the node is on the ``special path'' (i.e., the path from the root to the $x^*$-th leaf), then $b_0\ne b_1$, and $s_0$ and $s_1$ are independent.
    
    \item Otherwise, $b_0=b_1$ and $s_0=s_1$.
\end{enumerate}

The properties also hold for the leaf nodes, which is sufficient to prove the correctness of the DPF.
We now see the how to ensure these properties.
We have the first lemma, which can be proved by a simple induction argument.

\begin{lemma}
    If on some particular node, $b_0=b_1$ and $s_0=s_1$, then the subtrees expanded based on $(s_0,b_0)$ and $(s_1,b_1)$ will be identical, regardless of $CV_1,\dots,CV_{\log n}$.
\end{lemma}

This lemma shows that we only need to focus on the ``special path''. We can sample the roots first by sampling two random strings $s_0,s_1$ and let $b_0$ and $b_1$ be two different bits. 
Then, we can just ``simulate'' the expansion process on the special path, and then set up the correction vector according to the target properties. 
Since on the $i$-th level of the special path, there will be only one side affected by the correction vector (because the bits are different).
Therefore, we can always set the correction vector to ensure that after applying the correction vector, the children on the special path still have different bits and independent random strings, while the children deviating from the path will become identical.
The algorithm is presented in Figure~\ref{fig:DPF} and an example is presented in Figure~\ref{fig:example-DPF}.


\paragraph{Analysis.}
The correctness can be verified by doing an induction proof from level $1$ to level $\log n$.
The security analysis is referred to~\cite{boyle2016function}. 
It is also clear to see that the key size is $\lambda+1+\log n\cdot (2\lambda+2)=O_\lambda(\log n)$.



 \section{Batch-PIR}

 \subsection{Motivation}
    So far, every PIR scheme we have seen only retrieves 1 bit at a time. 
    In many use cases, the client may want to fetch up to $Q$ database entries at the same time. 
    The navie solution is just to repeat the single-query algorithm $Q$ times.
    For instance, to compute Q queries using a single-query PIR scheme with $O(n)$ computation, it requires $O(Qn)$ computation.
    Batch-PIR aims to handle multiple parallel queries at the same time, reducing the
     amortized cost.
     
     
\subsection{A simple load-balancing scheme}

Given an $n$ bit long database and $Q=o(n)$ queries, we load-balance the database into $\frac{Q}{\log Q}$ buckets -- we use a hash function to hash each database entry to a bucket (by hashing their index).
Then, given the $Q$ queries, we again use the hash function to place the queries to the buckets. 
In expectation, each bucket will have $\log Q$ queries. 
Based on the balls-into-bins argument, each bucket will have no more than $\lambda \log Q$ queries with $1-\negl(\lambda)$ probability.
Therefore, we just do $\lambda \log Q$ PIR queries in each bucket (possibly dummy queries) to retrieve the target entries. 
This ensures the success probability is at least $1-\negl(\lambda)$.

\paragraph{Security.}
We are always making fix number of queries ($\lambda \log Q$ PIR queries in each bucket), so the scheme is secure by a reduction to the security of the underlying PIR scheme.

\paragraph{Cost.}
Moreover, say the underlying single-query PIR computation cost is linear in the size of the database.
We are making $\lambda \log Q$ queries to each bucket, and the total size of the buckets is just $n$. 
Therefore, the total computation cost is $O(\lambda \log Q n)$. 
So if $Q>\lambda \log Q$, this simple scheme saves computation.


     
     
\subsection{Cuckoo Hashing based scheme~\cite{angel2018pir}}

Angel et al.~\cite{angel2018pir} proposed SealPIR that uses cuckoo hashing to do batch PIR.
    
    \paragraph{Cuckoo Hashing}
    \begin{definition}[Cuckoo hashing]
        Given $n$ balls, $b$ buckets, and $w$
independent hash functions $h_0$, $\cdots$ , $h_{w}$ that map a ball to a
random bucket, compute $w$ candidate buckets for each ball by
applying the $w$ hash functions. For each ball $x$, place $x$ in any
empty candidate bucket. If none of the $w$ candidate buckets
are empty, select one at random, remove the ball currently in
that bucket ($x_{\text{old}}$), place $x$ in the bucket, and re-insert $x_{\text{old}}$. If
re-inserting $x_{\text{old}}$ causes another ball to be removed, this process
continues recursively until we finish the insertion or a maximum number of iterations is achieved.
    \end{definition} \
    
\paragraph{Batch PIR based on Cuckoo Hashing.}   
The scheme is as follows.
\begin{itemize}
    \item \textbf{Serer encoding.} Given an $n$ bit database, $b$ buckets, and $w$ hash functions, we hash each entry in the database (using their index as the key) to all $w$ candidate buckets and store it there.
    This results in a encoded database that each original entry is replicated $w$ times.
    The server will share the hash functions to the client.
    
    \item \textbf{Client scheduling.} Given the $Q$ queries, the client use the cuckoo hashing method to insert (or say, schedule) the queries to the buckets (again, using the indices as the keys).
    Our target is that each bucket has at most one query, and all query can be inserted in one of its candidate bucket.
    
    \item \textbf{Client query.}. Now the client just makes one query in each bucket. If the client successfully insert all queries earlier, it can then proceed to learn all the target entries because the server has inserted the entries in all the candidate buckets.
\end{itemize}

An example can be found in Figure~\ref{fig:sealpir}.
   
The authors used 3 hash functions for encoding and set the number of buckets $b = 1.5Q$. For $Q\geq 200$, the author showed that the chance of failure during
the scheduling phase is $\leq 2^{-40}$.
Notice that this is not cryptographically neligible. 
To enforce negligible failure probability, we can introduce a size $\lambda$ stash of the cuckoo hash table.
That is, the stash stores at most $\lambda$ elements that fail to be inserted. 
Then, the client also has to make additional $\lambda$ PIR queries to the whole database.
This ensures the failure probability to be $\negl(\lambda)$.

\paragraph{Cost Analysis.} 
Assume the underlying single-query PIR scheme is linear.
The client will make one query in each bucket and the total bucket size is $wn$.
Also, the client needs to make $\lambda$ additional query to the whole database to ensure negligible failure probability.
Then, the computation cost for the $Q$ queries are just $(w+\lambda)n$.

    
    
\begin{figure*}
    \includegraphics[scale=0.45]{scribimg_batchpir.png}
    \caption{An example of the cuckoo hashing based batch PIR. \label{fig:sealpir}}
\end{figure*}












\ignore{

%%%%%%%%%%%%%

Intuitively, this just applies all hash functions to an entry. If all buckets it gets hashed to are
taken, it will choose a random bucket, remove the ball currently in there and re-insert
using the same procedure. \\
\paragraph{Probabilistic Batch Codes}
\begin{definition}[Batch Code ~\cite{angel2018pir}]
    A (n, m, k, b)-batch code B takes as input a collection DB of n
    elements, and produces a set of m codewords, C, distributed
    among b buckets. Formally, $B : DB \rightarrow (C_0,..., C_{b})$, where
    $|Ci|$ is the number of codewords in bucket i, and the sum of
    codewords across all buckets is $m = \sum_{i=0}^{b-1}|Ci| \geq n$.
    The goal of these codes is two-fold. First, they ensure that any k elements
    from DB can be retrieved from the b buckets by fetching at most
    one codeword from each bucket. Second, they keep the number
    of total codewords, m, lower than $k \cdot n$.
\end{definition}
Batch codes incur a large network overhead by guaranteeing completeness in that it
is always possible to retrive k codewords by querying k distinct buckets. By adding possibility of failure p,
bandwidth can be shaved off at the cost of a chance of query failure. Applying this relaxation
results in a Probabilistic Batch Code, which is how SealPIR is able to encode a database
into multiple sub-databases that can be queried simultaneously with PIR. Informally, they are defined by 3 functions:
\begin{itemize}
    \item \textbf{\sf Encode(DB):} Split the database and replicate entries accordingly.
    \item \textbf{\sf GenSchedule(W):} Generate a query to each subdatabase such that all desired items are retrieved.
    \item \textbf{\sf Decode(I):} Extracts individual responses from the server response.
\end{itemize}
A formal definition and construction using reverse hashing can be found on page 6 of ~\cite{angel2018pir}


\subsection{The SealPIR scheme}

\paragraph{Intuition} The main idea is to build a \Pbc \ over the PIR database. The only major modifications
are to GenSchedule and Decode, where the equeries must be modified to be PIR queries. While failures in the query scheduling phase are
possible, the authors tune the parameters to make the likelihood very low.
\\
\paragraph{Notation}
Let \Pbc = $(\mathsf{Encode},\GenSched,\mathsf{Decode})$ be a Probabilistic Batch code constructed using Cuckoo hashing. Additionally,
Let PIR = (\ServerPre,\ClientQ,\ServerA,\ClientD) be a PIR scheme.

\paragraph{\sf SealPIRPreprocess} Given w independent hash functions $H = (h_1,...,h_w)$ and \DB, output b buckets $B = {B_1,...,B_b}$, where:
$$\sf B_i = SealPIRPreprocess(s_i),(s_0,...s_b) = encode(DB) $$
\paragraph{\sf SealPIRQuery} For a set of Q queries $q_1,...,q_b$, and Cuckoo hashing algorithm CK:
\begin{enumerate}
    \item Client computes $\sigma \leftarrow GenSchedule(Q)$
    \item if $\sigma \neq \perp$ goto (3) else  return failure
    \item Client computes $(q_1,...q_b) \leftarrow (ClientQuery(B_0,\sigma[0]),...,ClientQuery(B_Q,\sigma[b]))$ and sends the result to the server
\end{enumerate}
Where $\sigma \in \{\{1,....,b\}\}^b$ maps queries to the bucket the query should go to. $\sigma == \perp$ if there were two indices mapped to the same bucket.

\paragraph{\sf SealPIRAnswer} Server computes and sends $$r_i = \ServerA(B_i,\sigma[i]), \forall i \in [Q]$$ back to client.
\paragraph{\sf SealPIRDecode} To retreive the answer to the ith query, the client computes:
$$a_i \leftarrow \sf Decode(ClientDecode(r_i))$$

%%%%%%%%%%%%%



}
